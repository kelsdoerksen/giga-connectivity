{"Test set CV accuracies": [0.7037037037037037, 0.775, 0.6625, 0.6875, 0.775], "Average test set accuracy": 0.7207407407407407, "Average test set F1": 0.8113736390206998, "_timestamp": 1706626469.848984, "_runtime": 358.34342908859253, "_step": 1, "roc_table": {"_type": "table-file", "sha256": "a38d0d2941cb69929c8c68790aa5e590bc46a880292add34d1a3a7677cab5277", "size": 4266, "artifact_path": "wandb-client-artifact://ter5n7vtcgfz8khvo6bkbcywfng6z7mgeq3qxbwdd54tjbx3979ikcztt4vo59h872d9lyg414bxynp6012kc999gvfx3uwierym9mzwwo4lq17heyhy3mfgnpwnke9t:latest/roc_table.table.json", "_latest_artifact_path": "wandb-client-artifact://ter5n7vtcgfz8khvo6bkbcywfng6z7mgeq3qxbwdd54tjbx3979ikcztt4vo59h872d9lyg414bxynp6012kc999gvfx3uwierym9mzwwo4lq17heyhy3mfgnpwnke9t:latest/roc_table.table.json", "path": "media/table/roc_table_1_a38d0d2941cb69929c8c.table.json", "ncols": 3, "nrows": 226}, "_wandb": {"runtime": 358}}