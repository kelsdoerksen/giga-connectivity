Creating instance of Random Forest model...
Fitting model...
Evaluating model...
Model accuracy before any fine-tuning is: 0.7706725468577729
Running grid search cv...
True Positive is 548
True Negative is 144
False Positive is 173
False Negative is 42
False positive rate is 0.5457413249211357
True positive rate is 0.9288135593220339
False negative rate is 0.0711864406779661
True negative rate is 0.45425867507886436
Traceback (most recent call last):
  File "/Users/kelseydoerksen/code/giga-connectivity/run_pipeline.py", line 415, in <module>
    rf.run_rf(
  File "/Users/kelseydoerksen/code/giga-connectivity/classifiers/rf.py", line 172, in run_rf
    'accuracy': accuracy_score(y_test, tuned_probs),
  File "/Users/kelseydoerksen/opt/anaconda3/envs/giga/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "/Users/kelseydoerksen/opt/anaconda3/envs/giga/lib/python3.10/site-packages/sklearn/metrics/_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "/Users/kelseydoerksen/opt/anaconda3/envs/giga/lib/python3.10/site-packages/sklearn/metrics/_classification.py", line 95, in _check_targets
    raise ValueError(
ValueError: Classification metrics can't handle a mix of binary and continuous-multioutput targets