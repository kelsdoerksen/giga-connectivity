{"Test set CV accuracies": [0.691358024691358, 0.75, 0.7875, 0.7375, 0.6], "Average test set accuracy": 0.7132716049382716, "Average test set F1": 0.8069398564347555, "_timestamp": 1706225321.017218, "_runtime": 12.631801128387451, "_step": 1, "roc_table": {"_type": "table-file", "sha256": "762662d7114b13ad790cc824f1577053807db487c4d6747a7e3a1f8466c1a953", "size": 2826, "artifact_path": "wandb-client-artifact://3s3h5aihkbhfi7trd5coqigipqj9tkywbgb01tq1dkrwc1dnr68ok4q3r3ux3sni85h4b6rjv9vzt8x4qb0nnl3gkky4tzpot10gtzvcokb2cezam6l1z3xmdpxp72oq:latest/roc_table.table.json", "_latest_artifact_path": "wandb-client-artifact://3s3h5aihkbhfi7trd5coqigipqj9tkywbgb01tq1dkrwc1dnr68ok4q3r3ux3sni85h4b6rjv9vzt8x4qb0nnl3gkky4tzpot10gtzvcokb2cezam6l1z3xmdpxp72oq:latest/roc_table.table.json", "path": "media/table/roc_table_1_762662d7114b13ad790c.table.json", "ncols": 3, "nrows": 150}, "_wandb": {"runtime": 12}}