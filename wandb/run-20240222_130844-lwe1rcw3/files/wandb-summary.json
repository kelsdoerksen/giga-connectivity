{"Test set CV accuracies": [0.6039603960396039, 0.5445544554455446, 0.6019900497512438, 0.6218905472636815, 0.6069651741293532], "Average test set accuracy": 0.5958721245258854, "Average test set F1": 0.6704402124249522, "_timestamp": 1708603740.386227, "_runtime": 15.613518953323364, "_step": 1, "roc_table": {"_type": "table-file", "sha256": "44ea6741ccb0a921db4f5572d5daeeb0540f4b1ceb6fdf84695f0ee255d2fa22", "size": 17425, "artifact_path": "wandb-client-artifact://oye6a8y4ouv0s6jteqjkap7at5tgfhje49np4ip3z2swng1oipe0l2xuzz6rkitw73jeb1kes6y0wwn036f13o6hurr0c532tbxz6gcutbeqdy7s2opb7vsxqfm5o5o7:latest/roc_table.table.json", "_latest_artifact_path": "wandb-client-artifact://oye6a8y4ouv0s6jteqjkap7at5tgfhje49np4ip3z2swng1oipe0l2xuzz6rkitw73jeb1kes6y0wwn036f13o6hurr0c532tbxz6gcutbeqdy7s2opb7vsxqfm5o5o7:latest/roc_table.table.json", "path": "media/table/roc_table_1_44ea6741ccb0a921db4f.table.json", "ncols": 3, "nrows": 927}, "_wandb": {"runtime": 14}}