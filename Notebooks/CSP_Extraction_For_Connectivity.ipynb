{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kelsdoerksen/giga-connectivity/blob/main/CSP_Extraction_For_Connectivity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngz8zz9Gvbxh"
      },
      "source": [
        "## C01 - Use CSP embeddings\n",
        "\n",
        "Simple example of how to obtain pretrained CSP embeddings. Read the paper here:[https://arxiv.org/abs/2305.01118](https://arxiv.org/abs/2305.01118). Note that this notebook needs to be run with GPU enabled. To do this got to: \"Runtime -> Change runtime type\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tD7wze7andRh"
      },
      "outputs": [],
      "source": [
        "!rm -r sample_data .config # Empty current directory\n",
        "!git clone https://github.com/gengchenmai/csp.git . # Clone CSP repository"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drQnlZEDwBvA"
      },
      "source": [
        "Import required packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q72Ypu0Cr3Sc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "import sys\n",
        "sys.path.append('./main')\n",
        "\n",
        "from main.utils import *\n",
        "from main.models import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUi_LduKwDpA"
      },
      "source": [
        "Write helper function to load CPS models from checkpoint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eWV6S2SmsX_O"
      },
      "outputs": [],
      "source": [
        "def get_csp(path):\n",
        "    pretrained_csp = torch.load(path, map_location=torch.device('cpu'))\n",
        "\n",
        "    params = pretrained_csp['params']\n",
        "    loc_enc = get_model(\n",
        "                            train_locs = None,\n",
        "                            params = params,\n",
        "                            spa_enc_type = params['spa_enc_type'],\n",
        "                            num_inputs = params['num_loc_feats'],\n",
        "                            num_classes = params['num_classes'],\n",
        "                            num_filts = params['num_filts'],\n",
        "                            num_users = params['num_users'],\n",
        "                            device = params['device'])\n",
        "\n",
        "    model = LocationImageEncoder(loc_enc = loc_enc,\n",
        "                        train_loss = params[\"train_loss\"],\n",
        "                        unsuper_loss = params[\"unsuper_loss\"],\n",
        "                        cnn_feat_dim = params[\"cnn_feat_dim\"],\n",
        "                        spa_enc_type = params[\"spa_enc_type\"]).to(params['device'])\n",
        "\n",
        "    model.load_state_dict(pretrained_csp['state_dict'])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUtwfnVKwNsu"
      },
      "source": [
        "Download pretrained models. For details see here: [https://gengchenmai.github.io/csp-website/](https://gengchenmai.github.io/csp-website/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3rib-U9ztCCg"
      },
      "outputs": [],
      "source": [
        "!wget -O model_dir.zip 'https://www.dropbox.com/s/qxr644rj1qxekn2/model_dir.zip?dl=1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v3IDc8C9tZZr"
      },
      "outputs": [],
      "source": [
        "!unzip model_dir.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orlY0u8owb7w"
      },
      "source": [
        "Load CSP model. Using CSP model that is pre-trained grid location encoder on unlabelled fMoW training dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0HoKFM2atxM2"
      },
      "outputs": [],
      "source": [
        "path = '/content/model_dir/model_fmow/model_fmow_gridcell_0.0010_32_0.1000000_1_512_gelu_UNSUPER-contsoftmax_0.000050_1.000_1_0.100_TMP1.0000_1.0000_1.0000.pth.tar'\n",
        "model = get_csp(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_2atCMKFtOU-"
      },
      "outputs": [],
      "source": [
        "# Get [lon, lat] of schools as float.64 tensor to extract embeddings for\n",
        "\n",
        "def get_coords(df):\n",
        "  \"\"\"\n",
        "  Function to return coords of school locations\n",
        "  as 2D tensor to extract GeoCLIP embeddings for\n",
        "  in order lon, lat\n",
        "  \"\"\"\n",
        "\n",
        "  total_coords = []\n",
        "  for i in range(len(df)):\n",
        "    coord = torch.tensor((df.loc[i]['lon'], df.loc[i]['lat']))\n",
        "    total_coords.append(coord)\n",
        "\n",
        "  locations = torch.stack(total_coords)\n",
        "\n",
        "  return locations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T7tbcgdeQtVM"
      },
      "outputs": [],
      "source": [
        "# Processing data for locations for the embeddings to be extracted from\n",
        "aoi = 'BWA'\n",
        "split = 'Testing'\n",
        "aoi_df = pd.read_csv('{}Data_uncorrelated_fixed.csv'.format(split))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get coordinates for aoi of interest\n",
        "coords = get_coords(aoi_df)"
      ],
      "metadata": {
        "id": "gkGDGJZeERif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBWysaAewdpb"
      },
      "source": [
        "Use CSP model to obtain location embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ku9kf_0su0id"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    emb = model.loc_enc(convert_loc_to_tensor(coords.numpy()),return_feats=True).detach().cpu()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MYtxk8NCvr0M"
      },
      "outputs": [],
      "source": [
        "emb.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "identifying_info_df = aoi_df[['giga_id_school', 'connectivity', 'lat', 'lon']]\n",
        "emb_df = pd.DataFrame(emb.numpy())\n",
        "\n",
        "emb_df_labelled = pd.concat([identifying_info_df, emb_df], axis=1)\n",
        "emb_df_labelled['data_split'] = split"
      ],
      "metadata": {
        "id": "BTDPcooiEYS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Export to dataframe\n",
        "emb_df_labelled.to_csv('{}_CSPfMoW_embeddings_{}.csv'.format(aoi, split))"
      ],
      "metadata": {
        "id": "q2cd8TqDzF7V"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}