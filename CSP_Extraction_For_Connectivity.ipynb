{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kelsdoerksen/giga-connectivity/blob/main/CSP_Extraction_For_Connectivity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngz8zz9Gvbxh"
      },
      "source": [
        "## C01 - Use CSP embeddings\n",
        "\n",
        "Simple example of how to obtain pretrained CSP embeddings. Read the paper here:[https://arxiv.org/abs/2305.01118](https://arxiv.org/abs/2305.01118). Note that this notebook needs to be run with GPU enabled. To do this got to: \"Runtime -> Change runtime type\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tD7wze7andRh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e20d6571-ca9d-42db-edee-a489ff9f5a7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '.'...\n",
            "remote: Enumerating objects: 86, done.\u001b[K\n",
            "remote: Counting objects: 100% (86/86), done.\u001b[K\n",
            "remote: Compressing objects: 100% (69/69), done.\u001b[K\n",
            "remote: Total 86 (delta 26), reused 75 (delta 15), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (86/86), 1.58 MiB | 11.33 MiB/s, done.\n",
            "Resolving deltas: 100% (26/26), done.\n"
          ]
        }
      ],
      "source": [
        "!rm -r sample_data .config # Empty current directory\n",
        "!git clone https://github.com/gengchenmai/csp.git . # Clone CSP repository"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drQnlZEDwBvA"
      },
      "source": [
        "Import required packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Q72Ypu0Cr3Sc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "import sys\n",
        "sys.path.append('./main')\n",
        "\n",
        "from main.utils import *\n",
        "from main.models import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUi_LduKwDpA"
      },
      "source": [
        "Write helper function to load CPS models from checkpoint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "eWV6S2SmsX_O"
      },
      "outputs": [],
      "source": [
        "def get_csp(path):\n",
        "    pretrained_csp = torch.load(path, map_location=torch.device('cpu'))\n",
        "\n",
        "    params = pretrained_csp['params']\n",
        "    loc_enc = get_model(\n",
        "                            train_locs = None,\n",
        "                            params = params,\n",
        "                            spa_enc_type = params['spa_enc_type'],\n",
        "                            num_inputs = params['num_loc_feats'],\n",
        "                            num_classes = params['num_classes'],\n",
        "                            num_filts = params['num_filts'],\n",
        "                            num_users = params['num_users'],\n",
        "                            device = params['device'])\n",
        "\n",
        "    model = LocationImageEncoder(loc_enc = loc_enc,\n",
        "                        train_loss = params[\"train_loss\"],\n",
        "                        unsuper_loss = params[\"unsuper_loss\"],\n",
        "                        cnn_feat_dim = params[\"cnn_feat_dim\"],\n",
        "                        spa_enc_type = params[\"spa_enc_type\"]).to(params['device'])\n",
        "\n",
        "    model.load_state_dict(pretrained_csp['state_dict'])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUtwfnVKwNsu"
      },
      "source": [
        "Download pretrained models. For details see here: [https://gengchenmai.github.io/csp-website/](https://gengchenmai.github.io/csp-website/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "3rib-U9ztCCg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "143d262f-9185-499c-a3b3-d046daf3bed5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-07-22 21:28:58--  https://www.dropbox.com/s/qxr644rj1qxekn2/model_dir.zip?dl=1\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.81.18, 2620:100:6031:18::a27d:5112\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.81.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://www.dropbox.com/scl/fi/rdig1ezmywm9avc8qubi6/model_dir.zip?rlkey=p8k16a5ifi69e08rnvu8rvt86&dl=1 [following]\n",
            "--2024-07-22 21:28:58--  https://www.dropbox.com/scl/fi/rdig1ezmywm9avc8qubi6/model_dir.zip?rlkey=p8k16a5ifi69e08rnvu8rvt86&dl=1\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc0c9855630aba94f9c2cddfef42.dl.dropboxusercontent.com/cd/0/inline/CXOpDEXIcCenR2SR-ke8SO33rtanhYTiR5R1AQGsmJxOdzfV4KBFpT-GNONUTxUXL_f_bXQFHF-kxNN0MblM90y613cPiSsuW8zPDnYOaufvUqFhbI0rmmKAonEFz0F3Gypsc2zxlpT3u2vlrQDfRQ8p/file?dl=1# [following]\n",
            "--2024-07-22 21:28:59--  https://uc0c9855630aba94f9c2cddfef42.dl.dropboxusercontent.com/cd/0/inline/CXOpDEXIcCenR2SR-ke8SO33rtanhYTiR5R1AQGsmJxOdzfV4KBFpT-GNONUTxUXL_f_bXQFHF-kxNN0MblM90y613cPiSsuW8zPDnYOaufvUqFhbI0rmmKAonEFz0F3Gypsc2zxlpT3u2vlrQDfRQ8p/file?dl=1\n",
            "Resolving uc0c9855630aba94f9c2cddfef42.dl.dropboxusercontent.com (uc0c9855630aba94f9c2cddfef42.dl.dropboxusercontent.com)... 162.125.81.15, 2620:100:6023:15::a27d:430f\n",
            "Connecting to uc0c9855630aba94f9c2cddfef42.dl.dropboxusercontent.com (uc0c9855630aba94f9c2cddfef42.dl.dropboxusercontent.com)|162.125.81.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/CXNdmm5reL7umyHaAJi1QDijd-7Zcf8CGKNnmK0T8l1vTsRXUh1Isyo3w33X7HORm-5J9vlmHUXZ62gfGmyXNAjNQF_pZ4cwCx8gexB29RwiOBWY76H8jY7Dxj9ZESUUxnMBXLxt_tbaFM981_Cix9cMq4wSnv1G6q9uzDnvCXwF9RNpo2X2-j_XAdiR14dRa85uuLyXdKBDaqtZNqP2oA9I1IG2pj6nLsBuFk07lQmfEjnk5d5Xm4RWilXw6PDNuAfpM9ZvA0S5C-qNhQGm3-cncZzTYqbXjaNhnOxVex6vyrZDuYOahcpqZH9qiqinaAmL_mhLy9WfGBeT_rUBl-LjdTk8VYF6uH8AWa2l51TZmdDuc0gKCspUe3Vv5vPRpEQ/file?dl=1 [following]\n",
            "--2024-07-22 21:29:00--  https://uc0c9855630aba94f9c2cddfef42.dl.dropboxusercontent.com/cd/0/inline2/CXNdmm5reL7umyHaAJi1QDijd-7Zcf8CGKNnmK0T8l1vTsRXUh1Isyo3w33X7HORm-5J9vlmHUXZ62gfGmyXNAjNQF_pZ4cwCx8gexB29RwiOBWY76H8jY7Dxj9ZESUUxnMBXLxt_tbaFM981_Cix9cMq4wSnv1G6q9uzDnvCXwF9RNpo2X2-j_XAdiR14dRa85uuLyXdKBDaqtZNqP2oA9I1IG2pj6nLsBuFk07lQmfEjnk5d5Xm4RWilXw6PDNuAfpM9ZvA0S5C-qNhQGm3-cncZzTYqbXjaNhnOxVex6vyrZDuYOahcpqZH9qiqinaAmL_mhLy9WfGBeT_rUBl-LjdTk8VYF6uH8AWa2l51TZmdDuc0gKCspUe3Vv5vPRpEQ/file?dl=1\n",
            "Reusing existing connection to uc0c9855630aba94f9c2cddfef42.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 94186705 (90M) [application/binary]\n",
            "Saving to: ‘model_dir.zip’\n",
            "\n",
            "model_dir.zip       100%[===================>]  89.82M  16.0MB/s    in 7.0s    \n",
            "\n",
            "2024-07-22 21:29:08 (12.8 MB/s) - ‘model_dir.zip’ saved [94186705/94186705]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -O model_dir.zip 'https://www.dropbox.com/s/qxr644rj1qxekn2/model_dir.zip?dl=1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "v3IDc8C9tZZr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3f947aa-7e1d-44ff-c70b-8318c72b3acc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  model_dir.zip\n",
            "   creating: model_dir/\n",
            "  inflating: __MACOSX/._model_dir    \n",
            "  inflating: model_dir/.DS_Store     \n",
            "  inflating: __MACOSX/model_dir/._.DS_Store  \n",
            "   creating: model_dir/model_inat_2018/\n",
            "  inflating: __MACOSX/model_dir/._model_inat_2018  \n",
            "   creating: model_dir/model_fmow/\n",
            "  inflating: __MACOSX/model_dir/._model_fmow  \n",
            "  inflating: model_dir/model_inat_2018/.DS_Store  \n",
            "  inflating: __MACOSX/model_dir/model_inat_2018/._.DS_Store  \n",
            "  inflating: model_dir/model_inat_2018/model_inat_2018_gridcell_0.0010_32_0.1000000_1_512_leakyrelu_contsoftmax_ratio0.050_0.000500_1.000_1_1.000_TMP20.0000_1.0000_1.0000.pth.tar  \n",
            "  inflating: __MACOSX/model_dir/model_inat_2018/._model_inat_2018_gridcell_0.0010_32_0.1000000_1_512_leakyrelu_contsoftmax_ratio0.050_0.000500_1.000_1_1.000_TMP20.0000_1.0000_1.0000.pth.tar  \n",
            "  inflating: model_dir/model_inat_2018/model_inat_2018_gridcell_0.0010_32_0.1000000_1_512_leakyrelu_UNSUPER-contsoftmax_0.000500_1.000_1_1.000_TMP20.0000_1.0000_1.0000.pth.tar  \n",
            "  inflating: __MACOSX/model_dir/model_inat_2018/._model_inat_2018_gridcell_0.0010_32_0.1000000_1_512_leakyrelu_UNSUPER-contsoftmax_0.000500_1.000_1_1.000_TMP20.0000_1.0000_1.0000.pth.tar  \n",
            "  inflating: model_dir/model_fmow/.DS_Store  \n",
            "  inflating: __MACOSX/model_dir/model_fmow/._.DS_Store  \n",
            "  inflating: model_dir/model_fmow/model_fmow_gridcell_0.0010_32_0.1000000_1_512_gelu_UNSUPER-contsoftmax_0.000050_1.000_1_0.100_TMP1.0000_1.0000_1.0000.pth.tar  \n",
            "  inflating: __MACOSX/model_dir/model_fmow/._model_fmow_gridcell_0.0010_32_0.1000000_1_512_gelu_UNSUPER-contsoftmax_0.000050_1.000_1_0.100_TMP1.0000_1.0000_1.0000.pth.tar  \n",
            "  inflating: model_dir/model_fmow/model_fmow_gridcell_0.0010_32_0.1000000_1_512_gelu_contsoftmax_ratio0.050_0.000050_1.000_1_0.100_TMP1.0000_1.0000_1.0000.pth.tar  \n",
            "  inflating: __MACOSX/model_dir/model_fmow/._model_fmow_gridcell_0.0010_32_0.1000000_1_512_gelu_contsoftmax_ratio0.050_0.000050_1.000_1_0.100_TMP1.0000_1.0000_1.0000.pth.tar  \n"
          ]
        }
      ],
      "source": [
        "!unzip model_dir.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orlY0u8owb7w"
      },
      "source": [
        "Load CSP model. Using CSP model that is pre-trained grid location encoder on unlabelled fMoW training dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "0HoKFM2atxM2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "223a1e34-23c6-44a0-a7cb-59618ccdcdaa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/./main/module.py:98: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  nn.init.xavier_uniform(self.linear.weight)\n"
          ]
        }
      ],
      "source": [
        "path = '/content/model_dir/model_fmow/model_fmow_gridcell_0.0010_32_0.1000000_1_512_gelu_UNSUPER-contsoftmax_0.000050_1.000_1_0.100_TMP1.0000_1.0000_1.0000.pth.tar'\n",
        "model = get_csp(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "_2atCMKFtOU-"
      },
      "outputs": [],
      "source": [
        "# Get [lon, lat] of schools as float.64 tensor to extract embeddings for\n",
        "\n",
        "def get_coords(df):\n",
        "  \"\"\"\n",
        "  Function to return coords of school locations\n",
        "  as 2D tensor to extract GeoCLIP embeddings for\n",
        "  in order lon, lat\n",
        "  \"\"\"\n",
        "\n",
        "  total_coords = []\n",
        "  for i in range(len(df)):\n",
        "    coord = torch.tensor((df.loc[i]['lon'], df.loc[i]['lat']))\n",
        "    total_coords.append(coord)\n",
        "\n",
        "  locations = torch.stack(total_coords)\n",
        "\n",
        "  return locations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "T7tbcgdeQtVM"
      },
      "outputs": [],
      "source": [
        "# Processing data for locations for the embeddings to be extracted from\n",
        "RWA_df = pd.read_csv('RWA_id_info.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get coordinates for aoi of interest\n",
        "coords = get_coords(RWA_df)"
      ],
      "metadata": {
        "id": "gkGDGJZeERif"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBWysaAewdpb"
      },
      "source": [
        "Use CSP model to obtain location embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Ku9kf_0su0id"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    x = model.loc_enc(convert_loc_to_tensor(coords.numpy()),return_feats=True).detach().cpu()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "identifying_info_df = RWA_df[['giga_id_school', 'connectivity', 'lat', 'lon', 'split', 'fid']]\n",
        "emb_df = pd.DataFrame(x.numpy())\n",
        "emb_df_labelled = pd.concat([identifying_info_df, emb_df], axis=1)"
      ],
      "metadata": {
        "id": "BTDPcooiEYS4"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into Train/Test/Val\n",
        "emb_train = emb_df_labelled[emb_df_labelled['split'] =='Train']\n",
        "emb_test = emb_df_labelled[emb_df_labelled['split'] =='Test']\n",
        "emb_val = emb_df_labelled[emb_df_labelled['split'] =='Val']"
      ],
      "metadata": {
        "id": "q2cd8TqDzF7V"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Export to dataframe\n",
        "emb_train.to_csv('RWA_CSP_embeddings_TrainingData.csv')\n",
        "emb_test.to_csv('RWA_CSP_embeddings_TestingData.csv')\n",
        "emb_val.to_csv('RWA_CSP_embeddings_ValData.csv')"
      ],
      "metadata": {
        "id": "3YuyZeX6WJCe"
      },
      "execution_count": 13,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}